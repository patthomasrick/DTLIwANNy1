FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=16 8 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (16, 4, 5.00000000000000000000e-01) (16, 4, 5.00000000000000000000e-01) (16, 4, 5.00000000000000000000e-01) (16, 4, 5.00000000000000000000e-01) (16, 4, 5.00000000000000000000e-01) (16, 4, 5.00000000000000000000e-01) (16, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (8, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.77176107158902773620e+00) (1, 3.56394022428482948328e+00) (2, -5.03654787899801337225e-01) (3, 8.91257576735352552433e-02) (4, 2.27606393489995395552e-01) (5, 3.53281777528704543645e-01) (6, -3.49903846356428793740e-01) (7, 1.42193414468581302845e-01) (8, -2.05561944503155902275e-01) (9, -5.26700902714934215965e+01) (10, -1.64186644727695396639e+00) (11, -2.88045681157710398157e-01) (12, -5.92978824076220711881e-02) (13, 1.76121370504772167820e-01) (14, 5.34778385424457791686e+00) (15, 3.19870252759376860752e-01) (0, -7.73978981893161854799e+00) (1, -2.50361464710770889042e+01) (2, -1.80031617140192268245e+00) (3, 2.61485998953491283192e-01) (4, 3.28028902253840681791e-01) (5, 5.50640065288547253530e-01) (6, -2.51642883229452962723e+00) (7, 2.24129793119296483184e+00) (8, 1.72453797975777489704e+00) (9, -5.77752267809058484005e+00) (10, -6.37448640133678412489e-01) (11, 6.86777840937648903497e-02) (12, 3.31946059413490923706e-01) (13, 2.40521253928393807797e+00) (14, 9.96724524276790901922e+01) (15, 1.01624176354924844468e+00) (0, -3.73140147364507299699e+01) (1, -3.55854279332571863392e+01) (2, -1.31278197787168227073e+00) (3, 1.05242412060531809193e-01) (4, 1.72193265161134445584e+00) (5, 8.08491472878667960522e-01) (6, 6.64781780965327229183e+00) (7, 1.72769109866291725730e+00) (8, 8.13093414363377009479e-01) (9, -2.34198372087571193845e+00) (10, -2.67755522191437433932e+00) (11, -1.57064089378838955824e+00) (12, -1.04412575727884870957e+00) (13, 2.12137504544326532807e-01) (14, 1.25363525347381941089e+01) (15, 2.27180213774053596509e+00) (0, -2.25183969488501709577e+01) (1, -3.15101472812053522432e+01) (2, -1.90680052687725865024e-01) (3, 1.72937097402587502959e-01) (4, 8.08242533972260757125e-01) (5, 1.49505466794818353549e+00) (6, 4.05396285851233351138e+00) (7, 1.74335034649574538435e+00) (8, 1.26302631582786806241e+00) (9, -5.31646860699758683211e+00) (10, -3.37632560730467767840e+00) (11, -1.40399591988222005590e+00) (12, -1.19792611776108404165e+00) (13, 1.34793287677004658409e-01) (14, 1.08793797740539126551e+01) (15, 3.18484779176993093586e+00) (0, -1.07069159378561824525e+01) (1, -3.43066243135593964553e+01) (2, -2.72830463933890854378e+00) (3, 4.42005700745636068150e-02) (4, 1.39354813066624161344e+00) (5, 5.88533467539651744538e-01) (6, 5.11805739280974858474e+00) (7, 9.21950171851325772643e-01) (8, 1.31032294814520988702e+00) (9, -4.50178470229933580526e+00) (10, -9.58860899694778723301e-01) (11, -2.16865031130517443847e-01) (12, 6.88759017389009020604e-02) (13, 5.43527513548274110455e-01) (14, 1.84060061048109844251e+01) (15, 6.75545846132513116977e-01) (0, -2.73536551993001957328e+01) (1, -3.71821106693220428951e+01) (2, -1.25452958863056718286e+00) (3, 1.76921365899905175256e-01) (4, 5.69144522053779633453e-01) (5, 8.89915533443124795454e-01) (6, 6.27264609587398513924e+00) (7, 9.86509154817490352407e-01) (8, 7.05018346962444586445e-01) (9, -2.54857666444695585284e+00) (10, -2.79695982008850219103e+00) (11, -1.21069745477724532989e+00) (12, -1.16569682590825585145e+00) (13, 2.65892098644068652913e-01) (14, 2.00809507393395172414e+01) (15, 2.23855266519721007867e+00) (0, -1.33056386530526049583e+00) (1, 2.64636646517020901470e+00) (2, -4.11412766387662942602e-01) (3, 3.19758314155573042381e-01) (4, 2.19919460272515354671e-01) (5, 3.39042468421297205072e-01) (6, 9.38434496016684049913e-01) (7, 1.27864779931838024041e+00) (8, 3.70445485721572154159e-01) (9, -1.04615206583644795302e+01) (10, -7.68642707759044863103e-01) (11, 2.55415452547671284478e-01) (12, 7.41145793879823600037e-01) (13, 5.44390654581921751287e+00) (14, 1.46181631497584429979e+01) (15, 7.31856173610274440833e-01) (16, -1.04027797818075839587e+02) (17, -1.75662825834820530702e+01) (18, -2.45960019144026231785e+00) (19, -2.11861606821037051773e+00) (20, -8.95531662231933545115e+00) (21, -1.80883282312995419261e+00) (22, -1.99457158602651070112e+01) (23, 9.08101112887591455092e+00) 
