FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=30 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (30, 4, 5.00000000000000000000e-01) (30, 4, 5.00000000000000000000e-01) (30, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (4, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.57718814794601813745e+00) (1, -7.89673603099608634182e+00) (2, 1.40384164265145994221e+00) (3, -1.61583821477085698426e+00) (4, -2.73463537610306950398e-01) (5, -3.47077320507577724573e-01) (6, -2.03585644633075352194e-01) (7, 2.18643926877144484378e-01) (8, 2.93035057854458935722e-01) (9, -3.60036295109531223613e-02) (10, -1.37567843089971136861e-01) (11, 6.25758724361957785476e-01) (12, 1.05260126847529322802e+00) (13, 1.28796031725600723661e+00) (14, -2.22008701740083003173e+00) (15, 3.90076015369953343903e-01) (16, 8.10265816808562799878e-01) (17, 5.10840939034559937681e+00) (18, -3.98487876044833422284e+00) (19, -1.41912752492851463870e+01) (20, -4.18883155283988628526e+00) (21, -3.17961854294715040581e+00) (22, -4.48297763260418946629e+00) (23, -8.19449040847364074125e+00) (24, -5.25796928414577258160e-01) (25, -1.00587611310404412279e+00) (26, -4.05411583129921607171e-02) (27, 1.27866439852991464754e+00) (28, 7.98412754168042511083e+01) (29, 2.20074181418985714842e+00) (0, 2.33959385857317414548e+00) (1, -6.17894140607742542670e+02) (2, -9.22795210211270529044e+01) (3, -3.27347522816344792318e+02) (4, -4.70853152863711343912e+00) (5, -2.37598344764085966929e+00) (6, -4.36955564789599723574e-02) (7, 9.04134580063405857153e-01) (8, 9.49187528006524727786e-01) (9, 1.73501067456486546270e+00) (10, 9.42954641753901201540e-01) (11, 2.87080662581283929669e+00) (12, 3.36425547064019037080e+00) (13, 3.40666495822857129383e+00) (14, 1.78536369097621760993e+00) (15, -7.44935161165100168112e-01) (16, 2.68166721700771315540e+00) (17, 9.67563551598720983371e-01) (18, -1.63482882561141007471e+00) (19, -3.95669311266853451770e+00) (20, -1.66205841645463658907e+00) (21, -1.41538085260467827453e+00) (22, -2.05994813408648091979e+00) (23, 4.84603790429626313241e-01) (24, 5.32038408239546511957e-01) (25, -1.58323338693347670514e+00) (26, 5.01280918040044767281e+01) (27, 4.14919050982029880004e+00) (28, 1.05768819705366922790e+03) (29, 3.88405801944973960715e+00) (0, 4.45643385242026912607e+00) (1, -1.19052606057059477962e+01) (2, -7.16280931050748215227e+00) (3, -1.75769461343155839472e+01) (4, -2.64834366434768675447e+00) (5, -3.17846258777405710205e+00) (6, -1.46031445184960766426e+01) (7, -1.17551552278720761180e+00) (8, 1.05794069508054966455e+00) (9, 8.23303740416281737424e-01) (10, 1.67912888464844556324e+00) (11, 4.35901788236495324469e+00) (12, 3.71785455433987932494e+00) (13, 2.60906346935625643724e+00) (14, 2.52854474926711336735e+00) (15, 1.41203826445895064268e+00) (16, 1.23155844197838826304e+00) (17, 1.93893449439171883242e+00) (18, -5.52110615941693527731e+00) (19, -8.03711876241054845593e+00) (20, -2.94416525734800149650e+00) (21, -1.21362229867587956278e+00) (22, -1.39756358307173167432e+00) (23, 5.39841514458397231380e-01) (24, 9.56846877037476284400e-01) (25, 2.20115069631750204238e+00) (26, 1.25208256439440468455e+01) (27, -1.31867129835180285635e-01) (28, 6.33414739170416325464e+01) (29, 4.65781489871967657734e+00) (30, -5.21342484340384544339e+01) (31, -2.03067514181554997776e+01) (32, -1.26005355632998643500e+01) (33, 6.49031594179191895222e+00) 
