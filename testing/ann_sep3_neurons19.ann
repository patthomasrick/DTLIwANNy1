FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 20 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (4, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (20, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.77039000969520743389e+00) (1, -8.08337316905301328518e+00) (2, -3.22105270335319193720e+00) (3, 3.34402180245254676549e+00) (0, -5.32698414619814144544e+01) (1, 6.10499641790444336209e+00) (2, 3.29210708150001948979e+02) (3, 4.47819411187320248757e+00) (0, 3.10788130483487412548e+00) (1, -4.47689727713348784022e+00) (2, -8.16752435584445493078e+01) (3, 2.42552457887206207587e+00) (0, 2.67411597681263257797e+00) (1, 3.33092832898420798671e+00) (2, -1.49637206097748993727e+01) (3, 6.08589911432011465564e-01) (0, 2.15381889416281024907e+00) (1, -7.93768024220184642559e+00) (2, 1.93102420547017636920e+01) (3, 2.82807141838946662915e+00) (0, 5.87966821483519996860e+00) (1, 1.49707845941687446611e+03) (2, 1.50000000000000000000e+03) (3, 3.17498536511003770499e+00) (0, 1.49999176747488309047e+03) (1, 1.49707845941687446611e+03) (2, 1.50000000000000000000e+03) (3, 9.39317143881890714852e+00) (0, 4.74280473271635649724e+00) (1, 1.49707845941687446611e+03) (2, 1.50000000000000000000e+03) (3, 2.57203563424152870098e+00) (0, -2.00063006767987872081e+01) (1, 8.50179316845574639672e+00) (2, 1.82734216236296305169e+02) (3, 2.18749567551128487608e+00) (0, 3.45256353754974254500e+00) (1, 3.40641405653439788281e+00) (2, -7.66937505589044690169e+02) (3, 4.50006682245132161313e+00) (0, 2.73704276713135641330e+00) (1, -5.70072319108626235362e+00) (2, -4.73744434878010167722e+01) (3, 2.59639711294454000878e+00) (0, 5.72674164675911701039e+00) (1, 7.00724479889639528807e+00) (2, -2.69209323826840396521e+01) (3, 1.68476015925930400208e+00) (0, 3.19248408397791365587e+01) (1, -6.94305594878611920251e+00) (2, -1.50000000000000000000e+03) (3, 4.69927248493830873599e+00) (0, 7.27963048500003218066e+00) (1, -4.13285187288415567508e+00) (2, -2.39146895650962790114e+02) (3, 3.82096535365607792301e+00) (0, 6.69413821133413922126e+00) (1, -4.11747704389874158437e+00) (2, -1.99810818961378544145e+02) (3, 3.18500254539197635850e+00) (0, 1.56512333804699395046e+01) (1, 5.45715488820010889981e+01) (2, -6.32002398273547328245e+02) (3, -1.25594401712021550566e+01) (0, -2.45019952386090755780e+00) (1, -2.47493423848988705060e+01) (2, -2.31158502168721810222e+02) (3, 1.06534055360480710561e+01) (0, -2.65173211985140397928e+01) (1, -9.18877941002620168831e+00) (2, 1.01434807596876126468e+02) (3, 7.32594082188098294495e+00) (0, -1.83496027576137721304e+00) (1, -6.71627041973928218255e+00) (2, -1.66450000134865774726e+02) (3, 5.39275469141515717553e+00) (4, -1.26308737723028166045e+01) (5, -4.66254738807768731590e+01) (6, -3.68623930795056153897e+00) (7, 3.77169187238461933731e+00) (8, -2.37531443314079808715e+01) (9, 3.92582790983477147861e+00) (10, 7.64879646730662798859e+00) (11, 3.66970812273923341351e+00) (12, 1.25673307746551206066e+01) (13, 6.60708126254456260540e+01) (14, -4.58048699271637627106e+00) (15, 3.79354841548045218502e+00) (16, -9.80997811765658411787e+01) (17, -3.00245159362090241473e+01) (18, -5.86512819560602771674e+00) (19, 1.95137139677549420469e+01) (20, 4.27886136949243010008e+01) (21, 3.16215891552540853127e+01) (22, -5.50374252008059769992e+01) (23, 6.25573164682715621154e+00) 
