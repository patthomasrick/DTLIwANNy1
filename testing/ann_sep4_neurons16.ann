FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=5 17 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (5, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (17, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.52559186373626349820e+01) (1, -5.78803656611353467554e+00) (2, 8.22265614013172108088e-01) (3, 5.52201323581840313182e+01) (4, -2.21774520299380384358e+00) (0, -1.73352425060176926763e+01) (1, 2.93290116881962337203e+00) (2, -5.14772502397551012798e-01) (3, 8.81217667651237803739e+01) (4, -5.54428661216021545499e+00) (0, -1.56143006529295718110e+01) (1, 1.22194386049692447216e+01) (2, -1.81045927469834881662e-02) (3, 9.48233120633837387459e+01) (4, -8.98329317161676144110e+00) (0, -3.56301065378491585989e+01) (1, 6.43824588590196711380e+00) (2, 1.44910796487483626294e+01) (3, 7.05699547242350490706e+02) (4, 1.87366481407216234345e+00) (0, 5.95815343306146516511e+01) (1, 1.47560196030304169312e+01) (2, -1.57224848754435608811e+00) (3, -9.20206136758431398448e+02) (4, -4.87183925076136770116e+00) (0, -7.81257023531078420575e+00) (1, 2.86378115649890574446e+01) (2, -2.28116087871765174100e+01) (3, -2.21728219961650637515e+02) (4, 1.82667492197979397517e+00) (0, -1.07986427920433794014e+01) (1, 1.82384905955027925017e+01) (2, -7.99589253604203853421e-01) (3, 1.17856266271236762577e+02) (4, -1.08558408167036333225e+01) (0, -4.13269859953956313348e+01) (1, 1.63554150722300217780e+00) (2, 1.60400950668797577237e+01) (3, 7.18780186008253735963e+02) (4, -5.87237478681459190710e+00) (0, -6.79546817554274174000e+00) (1, 1.20019287545694517405e+01) (2, -1.10980617331497000144e+00) (3, 9.13600778397335773207e+01) (4, -1.08942666881746088592e+01) (0, -1.22180338257990825923e+02) (1, 4.00699683636534964570e-01) (2, -3.00174564906109697660e+00) (3, 4.56100488737881391899e+02) (4, 3.04667641733171234986e-01) (0, -1.78989724539770094225e+01) (1, 3.44738517135059074903e+00) (2, -4.69839648664933162703e-01) (3, 9.90148164765235350160e+01) (4, -5.82242715824143264314e+00) (0, -1.57474342131663753719e+01) (1, 1.09376725377535546357e+01) (2, -7.83029938690712745686e-02) (3, 1.00071413320872409258e+02) (4, -8.85307522956842696260e+00) (0, -1.61004667820341418327e+00) (1, 5.54116900132388607858e+01) (2, 1.01444975129917214218e+01) (3, -6.54711279156427281123e+02) (4, -7.03395453304060236377e+00) (0, -1.90112066289706724831e+01) (1, 4.62352860952617383816e+00) (2, 1.23037758755382253817e-01) (3, 1.07861887795768140563e+02) (4, -7.18557930443472603343e+00) (0, -2.11570020542300412103e+01) (1, 3.27256069062554244553e+00) (2, -4.86675622807895558175e-01) (3, 1.38453604853963383903e+02) (4, -3.56397303162510903363e+00) (0, -3.22759025910180241681e+00) (1, -3.62979963430486329834e-01) (2, -1.13539729173657608641e+01) (3, -1.32972039953796468126e+02) (4, 1.97446743890695031176e+00) (5, -2.79121372941588283823e+01) (6, -1.59864450769020550069e+02) (7, 1.10101404626746571580e+02) (8, -3.70755037218875316274e-02) (9, 4.56419865154277744068e+01) (10, -4.32832666769890508363e+01) (11, 2.26777924800100578295e+02) (12, 5.21578618159970197610e+00) (13, 1.43777684635769355737e+03) (14, -1.51610722038021208391e+02) (15, 9.78814245843042954220e+02) (16, 4.01483158603668982778e+02) (17, -3.61908716631199780522e+01) (18, 1.45000000000000000000e+03) (19, -3.56508050760462310791e+02) (20, -3.15172847340630823965e+00) (21, 6.91839221621933031514e+00) 
