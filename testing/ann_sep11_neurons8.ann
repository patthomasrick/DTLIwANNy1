FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 4, 5.00000000000000000000e-01) (12, 4, 5.00000000000000000000e-01) (12, 4, 5.00000000000000000000e-01) (12, 4, 5.00000000000000000000e-01) (12, 4, 5.00000000000000000000e-01) (12, 4, 5.00000000000000000000e-01) (12, 4, 5.00000000000000000000e-01) (12, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.91997772337948813259e+00) (1, -2.36483656830425958972e+00) (2, -5.18977102597617201418e-01) (3, -6.51227043555476003966e-01) (4, 9.17336508279177387237e+00) (5, -2.28675567435024790219e-01) (6, -6.73390251537994455333e+00) (7, -2.89971012810381534308e+00) (8, -1.82800822613643787484e+00) (9, -1.18863851912304885339e+00) (10, 4.72234872015097550957e+00) (11, 9.82085800261432440017e-01) (0, -9.13267173849674804842e+01) (1, -3.59344889027879421661e+00) (2, -1.90316746203192138642e-01) (3, -3.45302836591658346421e+00) (4, 6.32628963903188612505e+00) (5, 4.91354195989677999812e-01) (6, -9.76244315880599344837e+00) (7, -3.10893786604508548521e+00) (8, -2.10740153552103937074e+00) (9, -6.70641589152624062464e-01) (10, 5.99678673664019834533e-01) (11, 6.25962794497772256896e-01) (0, -6.05828814919040965492e+01) (1, -1.10356767449697041883e+01) (2, 9.55158357111274974871e-02) (3, 1.41359659970749906854e+00) (4, 1.93089167874206069087e+00) (5, 2.33496116853495916388e+00) (6, -5.54678712536693030444e+00) (7, -1.27585760168038842011e+00) (8, -3.48659552222806867761e-01) (9, 4.60610423165062599082e+00) (10, 7.85052439769057031071e+01) (11, 2.15209246722781832872e+00) (0, 5.83062960820798181771e+00) (1, -2.55293353278097434611e+00) (2, 3.27362402168559496474e-01) (3, 1.56788264359102938461e-02) (4, 1.87079963819182193419e+00) (5, -1.63973942152164792185e-02) (6, -9.68455910367210748291e+00) (7, -4.68095683450018729133e+00) (8, -8.08245567054851399291e-01) (9, 1.25756187489898163534e+01) (10, 1.34383320007519415640e+01) (11, 1.43207082252745232509e+00) (0, -9.11179301840601993945e+01) (1, -1.96020801562648401273e+01) (2, -6.64385513997595111846e+00) (3, -3.86356991743207345280e+00) (4, 5.75473105923229066860e+00) (5, -1.86347644849481963725e-01) (6, -8.04282811430777577755e+00) (7, -4.44136186399626797794e+00) (8, -1.40624157979732955503e+00) (9, -1.45161174673588377892e+00) (10, 1.02912611508152918027e+00) (11, 5.97632254441466836958e-01) (0, -4.93839758543960272164e+01) (1, -1.18897449912765615920e+01) (2, 1.04971658134939069273e-01) (3, 8.00447019566734363494e-01) (4, 1.75554854537304527717e+00) (5, 2.28881148854354599109e+00) (6, -4.90713665063395954036e+00) (7, -1.33392131760523580120e+00) (8, -5.16385625865135811097e-01) (9, 4.50653495850182661542e+00) (10, 4.32857692832605422950e+01) (11, 2.19383945886118425506e+00) (0, -1.67249173235953136896e+01) (1, -4.43843046180997724548e+00) (2, -5.74996323422963584449e-01) (3, -7.43814529742665153655e-01) (4, 3.95241364646028392471e+00) (5, 1.00888630332743631235e-01) (6, -2.71610506414387913310e+01) (7, 1.55541615434598643475e+01) (8, -2.46878048098916735853e+00) (9, -1.60840351308278184383e+00) (10, 8.00142365930957666365e-01) (11, 4.91127982412644215060e-01) (0, -4.06947440214958575666e+01) (1, -6.70123785389606130281e+00) (2, 2.46878685597826774689e-01) (3, 6.68253448362424590234e-02) (4, 1.90555734519043085129e+00) (5, 1.66388867380173777200e+00) (6, -6.31363076873383644028e+00) (7, -2.59181747076947077701e+00) (8, -9.43674793474123529968e-01) (9, 8.15367007951555322620e+00) (10, 7.29461491351547834938e+01) (11, 1.92281477946617740393e+00) (12, -1.61670864982518942554e+01) (13, -1.53431819999923646947e+02) (14, -1.37650429542347190193e+01) (15, -7.75519967030520174234e+00) (16, 1.98125485841652448471e+02) (17, -9.39786566151598101726e+00) (18, 3.42925045364231948497e+01) (19, -2.91633606966994873844e+00) (20, 7.90084315023602634653e+00) 
