FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=34 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (34, 4, 5.00000000000000000000e-01) (34, 4, 5.00000000000000000000e-01) (34, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (4, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.01618260427505324728e-01) (1, -4.82092824975790090747e+00) (2, -2.14663706435725991639e+01) (3, -1.32782410535340620328e+01) (4, -3.81577922060757712686e+00) (5, -9.02458140488859417161e-01) (6, -7.17937295091097937849e-01) (7, -6.67392079484408595746e-01) (8, -9.00336686915359368788e-02) (9, 1.39871032662376271194e-01) (10, 5.22512455794448049673e-01) (11, -2.45551593247480895443e-02) (12, 1.61468464426265972955e-01) (13, 5.89429713333666116526e-01) (14, 1.75030329016367902639e+00) (15, 5.22475931573383345352e-01) (16, 2.25663444718930544797e-01) (17, 3.29078803806525932441e-01) (18, -1.86279730663721672379e-02) (19, -2.44055560023929862812e-01) (20, -4.78173594778875221678e-01) (21, -4.07056497122002713951e+00) (22, -2.14376610140334955545e+00) (23, -3.24238568101207047523e-01) (24, 5.11510103124109494210e-01) (25, 6.98580987409619158512e-01) (26, 6.29708956720449686273e-01) (27, 7.32741063851688134712e-01) (28, 8.65119236013260572982e-01) (29, 9.80801552533812515122e-01) (30, 8.52233445274270451364e+00) (31, -1.10925297099421102387e-01) (32, 4.80785074473452667121e+01) (33, 1.13198534898528269110e+00) (0, 1.12404316273132387494e+00) (1, -1.71549591908762955050e+00) (2, -4.74379177906365789852e+00) (3, -5.51532437561650823454e+00) (4, -2.19824813554120890302e+00) (5, 1.92363340080613620664e-01) (6, -2.27246465064702946046e-01) (7, -1.56567526884494545580e-01) (8, -2.78703882762867338752e-01) (9, 6.47065156162650700900e-01) (10, 6.02948196555821991360e-01) (11, 5.21834824630722393657e-01) (12, 5.06501022630563513260e-01) (13, 1.33330510752732855906e+00) (14, 3.98686174763451051106e+00) (15, 3.68599640122251992480e+00) (16, 1.12370165461434834420e+00) (17, 5.67213097407106126013e-01) (18, 4.47377034328457157120e-01) (19, -2.08822008825473776072e-01) (20, -1.95432259143095543585e+00) (21, -2.55686048621750083853e+00) (22, -2.65050039087139577276e+00) (23, -2.03509487221897211739e+00) (24, -1.77845932587850019679e+00) (25, -1.80477806065679491354e+00) (26, -2.46100536650121437532e+00) (27, -2.76751041480926129879e+00) (28, -5.93685995489399953584e+00) (29, -1.89752811823017086823e+00) (30, -2.04681241888472364998e-01) (31, 6.78938686766992538502e-01) (32, 2.57900664020712877544e+00) (33, 2.73010130726747446417e+00) (0, 2.27067964556738433046e+00) (1, -1.02904166586464188016e-01) (2, -9.29649025329349010249e-01) (3, -6.03763793635488621447e+00) (4, -8.72132916821163228782e-01) (5, 2.68668734820909860250e-01) (6, 2.10374258025048499476e-01) (7, -2.85297661458660256617e-01) (8, -3.80232944113291893018e-01) (9, 4.93777885292412677121e-01) (10, 5.55896825781925896237e-01) (11, 6.20383180067245132427e-01) (12, 5.00854526156416679505e-01) (13, 2.40810210299203752982e+00) (14, 4.08137837152382410011e+00) (15, 3.71091951113494022962e+00) (16, 9.46152404914597955354e-01) (17, 5.77625350267891857214e-01) (18, 3.84775846529913534422e-01) (19, -7.14704772900866952545e-02) (20, -1.83511906862955553876e+00) (21, -2.37089209387640531546e+00) (22, -2.29025676230530317312e+00) (23, -2.18976967964518598464e+00) (24, -2.07960384630576911036e+00) (25, -2.34856502057783211868e+00) (26, -2.31473654084390956243e+00) (27, -3.31376489286903153086e+00) (28, -3.30853430216792832042e+00) (29, -2.34765573334001409478e+00) (30, -2.35311485844592471750e+00) (31, 5.89596470815325512937e-01) (32, 2.55219346820597081660e+00) (33, 1.90551909723901569116e+00) (34, -2.26553203061327081969e+01) (35, -1.12803459305194824225e+01) (36, -1.59023378969683442108e+01) (37, 8.45602000573355461199e+00) 
