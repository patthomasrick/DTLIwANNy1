FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=27 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (27, 4, 5.00000000000000000000e-01) (27, 4, 5.00000000000000000000e-01) (27, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (4, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 9.06510256101856981559e+00) (1, -9.79546558642547735007e-03) (2, -6.33708366177497062210e+00) (3, -4.49982380259672432032e+00) (4, -7.76390673206980519439e-01) (5, -2.98266745662165433384e-01) (6, 4.25848741826095500418e-01) (7, 3.96590480846792214908e-01) (8, -6.60742495403657675856e-02) (9, 1.59699851066113125697e-02) (10, 1.12196672782034112537e+00) (11, 2.78902581708982300057e+00) (12, -6.48491930943827954437e-01) (13, 2.48050186158874153008e+00) (14, -1.89980227176028484970e-02) (15, -5.40279455127485763732e-01) (16, -3.49560170995154972928e+00) (17, -6.20567245738990358461e+00) (18, -1.08758202373333845436e+00) (19, -5.08421958356094827458e-01) (20, -3.55431304391945146470e-01) (21, 3.72541024163317247009e-01) (22, 4.36366762693532861395e-01) (23, 5.20191836700571230701e-01) (24, 2.09390938754312605496e+00) (25, 8.45587170585150857960e+01) (26, 1.16210800588240914522e+00) (0, 7.24678881962358989455e+00) (1, -5.44690329551086760418e-01) (2, -4.16466199673750203658e+00) (3, -4.52623404700199394313e+00) (4, -6.83549430518162859372e-01) (5, -3.55833599070547845766e-01) (6, 4.13475550544198322545e-01) (7, 7.19074248344192645810e-01) (8, 7.02198546185125033192e-02) (9, 5.52183510548526490513e-02) (10, 1.16905987146458234527e+00) (11, 2.46983663405084064024e+00) (12, -8.21685716353241502041e-02) (13, 2.39326724530913859113e+00) (14, 3.70608162459057990934e-02) (15, -5.79889438690908920471e-01) (16, -3.63260257674356479285e+00) (17, -6.17911463933475069155e+00) (18, -1.19051254241146931001e+00) (19, -5.80265060060827231325e-01) (20, -5.69471478257418728397e-01) (21, 3.10729343161029014642e-01) (22, 2.71348151185011654540e-01) (23, 6.28788660810125743517e-01) (24, 2.10508685286275953885e+00) (25, 8.08670343452879478718e+01) (26, 1.17094990432683743187e+00) (0, 2.47078546701442069988e+00) (1, -3.07384706516883170480e+01) (2, -3.43818182376297869496e+01) (3, -3.45942523009839817405e+01) (4, -2.75545504817477793225e+00) (5, 8.29228491105935661132e-01) (6, 1.40575047184369106290e+00) (7, 1.82159246807215691177e+00) (8, 2.70204970670648192410e+00) (9, 1.89436769032859642081e+00) (10, 2.18929164476768578496e+00) (11, 3.83923718126132174078e+00) (12, 1.93325067289004115523e+00) (13, 2.44518815500129838014e+00) (14, 6.63414537714823837611e-01) (15, -5.92878023746933324745e-01) (16, -1.36180477987446724164e+00) (17, -2.74150158073550365145e-01) (18, -1.25630973257736178184e+00) (19, 2.25282297866694269928e+00) (20, 3.44020479898152820031e-01) (21, -1.37281893451761494163e+00) (22, -9.23777595781873239744e-01) (23, -1.05186024758323770634e+00) (24, 1.78139081188140768752e+00) (25, 1.57004941041008265756e+01) (26, 2.29819238880106446743e+00) (27, -1.20664666034648515591e+01) (28, -2.08042078924239284277e+01) (29, -1.14348084861828507286e+01) (30, 9.83931156814145246869e+00) 
