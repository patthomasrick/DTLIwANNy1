FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 12 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.63969391498154806186e+01) (1, -4.81177629968924414072e+00) (2, 4.62702776584490660383e+00) (3, 1.55050280649223526375e+00) (4, -8.24846161273993949692e+00) (5, -4.05442627413456335717e+00) (6, 2.86604160347433056799e+00) (7, 1.31545199093082554320e+00) (0, -5.09725753799138345812e+01) (1, -1.01126484354576628988e+00) (2, 1.23434960423829114262e+01) (3, -4.87505272767218222896e-01) (4, -3.40031117878772581875e+00) (5, -4.75805876061404386945e+00) (6, -1.47104668978818295955e+02) (7, 9.41003759270350514932e-01) (0, -3.29240102503449847404e+01) (1, -7.59178491725789661437e-01) (2, 6.54588301022665586260e+00) (3, -5.88658140745640712233e-01) (4, -3.62376875069744208702e+00) (5, -8.80032500333203060450e+00) (6, 1.12738672847331748983e+01) (7, 8.99360564054940692102e-01) (0, -8.95045795899916498684e+01) (1, -6.39515107687506212386e+00) (2, 3.84080439179263111171e+00) (3, -7.93218373203327553611e-01) (4, -3.56399856098823430983e+00) (5, 1.94587611474759256680e+01) (6, 4.81800860937080074109e+02) (7, -5.15961718819751835596e-01) (0, -8.30016479119121441954e+00) (1, -4.68000011747790489736e-01) (2, 9.11819155947612181023e+00) (3, 7.36265359884258896450e-01) (4, -1.17706683837924970248e+01) (5, 2.53643171041985127090e+00) (6, 1.75868572464487016305e+01) (7, 1.90465270523834973027e+00) (0, -5.82557746954127395611e+01) (1, -5.45717295986147377107e-01) (2, 2.37875873375166406731e+01) (3, 5.29010451330270292658e+00) (4, -3.42995496320438642002e+00) (5, -8.97421173726720589059e+00) (6, -1.09983073568348771687e+02) (7, 9.23764127680048785507e-01) (0, 2.07921807160557881033e+00) (1, -1.15854001709746623483e+00) (2, 4.44277652102161013659e+00) (3, -4.67009401771462606678e-01) (4, -1.16781779812123733819e+01) (5, 6.82228530896421236918e+00) (6, 4.50514396757129702564e+01) (7, 6.92313126549380708497e-01) (0, -5.80096504800007082281e+01) (1, -1.06746837771238567427e+00) (2, 1.27584328176158869894e+01) (3, -3.03109249563938421002e-01) (4, -3.43411247908838035414e+00) (5, -2.77921808092770428189e+00) (6, -8.62581885467024562786e+01) (7, 9.93056591121814435930e-01) (0, 3.22183815728530476008e+01) (1, -2.12317251094429004787e-01) (2, 6.74797183701389879928e+00) (3, -1.70804110653616392224e-01) (4, -2.74078260835925675565e+01) (5, -9.13094587336498442198e+00) (6, 1.81401627102408156134e+01) (7, 1.23284913123543415914e+00) (0, -5.99472615311396168636e+01) (1, -1.01127381595035603645e+00) (2, 9.60685064800514787464e+00) (3, -7.61071090285491691496e-01) (4, -3.36772750569315038049e+00) (5, -2.61285731273467414226e+00) (6, 3.45484067855282095394e+00) (7, 1.05903070414406430544e+00) (0, -4.89749002092741534398e+01) (1, -5.53696404025260657811e-01) (2, 1.39771700332856365634e+01) (3, 4.19388045446291712892e+00) (4, -3.41586623922053389535e+00) (5, -3.32843399193170830230e+00) (6, -6.41882683537522211736e+01) (7, 9.75141339140628060633e-01) (8, -1.21523259113295090117e+00) (9, -2.84178411042383061158e+00) (10, 3.81535950881077479124e+00) (11, -8.23984621310694720364e+00) (12, -3.18463900665468679918e+00) (13, -1.88099499377254772980e+01) (14, -1.22884317562226641485e+01) (15, 2.58143296188051873941e+00) (16, -1.04358022532155558793e+01) (17, -2.43157546817818248641e+00) (18, -2.89343109174436685649e+00) (19, 1.39689919465582637059e+01) 
