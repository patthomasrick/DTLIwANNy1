FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=16 7 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (16, 4, 5.00000000000000000000e-01) (16, 4, 5.00000000000000000000e-01) (16, 4, 5.00000000000000000000e-01) (16, 4, 5.00000000000000000000e-01) (16, 4, 5.00000000000000000000e-01) (16, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (7, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.54796969754422590881e+01) (1, -1.31721377239552435157e+01) (2, -6.06999254093524148734e-02) (3, 1.15402291224342645748e-01) (4, 2.53578562830288722907e+00) (5, 6.63031271548876532940e-01) (6, 2.78079755517225768457e+00) (7, 1.08929945653408366546e+00) (8, 4.74219982701396247649e+00) (9, -4.09684307861699359421e+00) (10, -3.26345380310009547387e+00) (11, -1.59652211992467019108e+00) (12, -1.34408964045999823611e+00) (13, 2.42422239595077138041e-01) (14, 3.07219585389773763850e+00) (15, 2.00493651805861183846e+00) (0, -4.24147868314028784198e+01) (1, -9.51314714393784122137e+00) (2, 2.47007191313145350875e-02) (3, 6.09228443253534632240e-02) (4, 8.51845576843771712383e-01) (5, 7.82132214281563875602e-01) (6, 3.59617078035750248333e+00) (7, 3.79955299752559305659e+00) (8, -1.58622434729870531722e-01) (9, -4.23111691656893551539e+00) (10, -3.77298672380837984974e+00) (11, -1.48350129676665076772e+00) (12, -1.19177341775932910117e+00) (13, 6.60810097959059206119e-01) (14, 4.65913382806535469882e+00) (15, 2.01524144430247131865e+00) (0, -4.24787200921417280597e+01) (1, -9.56080277106930331854e+00) (2, -5.04034131633401411010e-02) (3, 1.11452580230577497078e-01) (4, 8.70681441804919020733e-01) (5, 8.66389325234894869254e-01) (6, 3.49752353608288579778e+00) (7, 3.80572848575915934077e+00) (8, -1.62598623329933855697e-01) (9, -4.20140959280914128016e+00) (10, -3.78783738496694155629e+00) (11, -1.49097272233955258081e+00) (12, -1.16263414116540553245e+00) (13, 5.17657286996635934706e-01) (14, 4.53175056614633309238e+00) (15, 2.03382866103735704399e+00) (0, -1.87683819863666876415e+01) (1, -3.37746377369057100282e+01) (2, -5.65816324954977328821e-02) (3, 1.72192162169697210450e-01) (4, 1.12051699966808815390e+00) (5, 8.97297281539510160897e-01) (6, 2.74760720833360005955e+00) (7, 1.02233204108098130192e+00) (8, 1.30191614907938402190e+00) (9, -6.58696461158907453637e+00) (10, -2.42001242735285893026e-01) (11, 3.22727568762373684397e-01) (12, 2.39795548461550461772e-01) (13, 3.33467197887397093226e+00) (14, 6.02754587016602272342e+01) (15, 1.18152096170179032875e+00) (0, 5.70158544082227969341e+00) (1, 1.90028243080192438264e+00) (2, -6.22571305204147867202e-03) (3, 1.25526544058496947187e-01) (4, 6.01963653788107344589e-01) (5, 5.62308121672860594664e-01) (6, -1.26910031637199316457e+00) (7, 9.40639076683293828829e-01) (8, 4.04893457452510319161e-01) (9, -1.16134307486807681897e+01) (10, -1.13310406965164411908e+00) (11, 9.19029943796726422889e-02) (12, 1.81673152044964325569e+00) (13, 6.34959821530003054590e+00) (14, 2.20596820840495446703e+01) (15, 8.95897473444694503186e-01) (0, -3.99742536044920342420e+01) (1, -1.41858445819776139984e+01) (2, -2.56508351522235882036e-02) (3, 1.05493723664575836385e-01) (4, 2.56701575769799550386e+00) (5, 9.19562418195097874829e-01) (6, 3.17177211386194457532e+00) (7, 8.34342829000554120356e-01) (8, 3.84799908923604228050e+00) (9, -4.01013817577355968780e+00) (10, -3.27162143761905133132e+00) (11, -2.41791405990836150153e+00) (12, -3.97577648646514514308e-01) (13, 3.65978906075773324780e-01) (14, 5.36423304641149556460e+00) (15, 1.94746715819909965717e+00) (16, -1.18253222420740033982e+00) (17, -1.29934232298204443978e+00) (18, -1.27800837520429633187e+00) (19, -2.51979368278961928240e+01) (20, -1.62270573647349571900e+01) (21, -7.77029765214974132981e-01) (22, 8.33130137445823848452e+00) 
